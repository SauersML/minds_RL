name: Analyze Evals

on:
  workflow_dispatch:
  workflow_run:
    workflows: ["Eval Science Pipeline"]
    types: [completed]

jobs:
  analyze:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success' }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download evals.tsv from Latest Eval Run
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: eval.yml
          name: eval-science-pack
          path: evals/
          search_artifacts: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: pip install pandas numpy matplotlib

      - name: Find Metrics File
        id: find-metrics
        run: |
          METRICS_FILE=$(find outputs -name "metrics.jsonl" -type f 2>/dev/null | head -1)
          if [ -n "$METRICS_FILE" ]; then
            echo "metrics_path=$METRICS_FILE" >> $GITHUB_OUTPUT
            echo "Found metrics file: $METRICS_FILE"
          else
            echo "No metrics.jsonl found in outputs/"
          fi

      - name: Run Analysis
        run: |
          METRICS_ARG=""
          if [ -n "${{ steps.find-metrics.outputs.metrics_path }}" ]; then
            METRICS_ARG="--metrics ${{ steps.find-metrics.outputs.metrics_path }}"
          fi
          python evals/analysis.py --input evals/evals.tsv --output_dir evals/results $METRICS_ARG

      - name: Publish Summary
        run: cat evals/results/analysis_summary.md >> $GITHUB_STEP_SUMMARY

      - name: Upload Analysis Results
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results
          path: |
            evals/results/analysis_stats.json
            evals/results/analysis_summary.md
            evals/results/analysis_plot.png
            evals/results/rewards_over_time.png
